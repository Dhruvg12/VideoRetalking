{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMepMhYEcRtsPs+AHhCEDhe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhruvg12/VideoRetalking/blob/main/SadTalker_Wav2Lip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "h5KIExHpUybM",
        "outputId": "5981c17e-226b-4b47-f966-0711dc425406"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-781939501.py, line 6)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-781939501.py\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    pip install -U pip\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "First Video with random face Video\n",
        "\n",
        "/content/video-retalking# python3 inference.py \\\n",
        "  --face /content/my_inputs/5Sec.mp4 \\\n",
        "  --audio /content/my_inputs/testaudio.wav \\\n",
        "  --outfile /content/my_outputs/test_result_safe.mp4\n",
        "[Info] Using cuda for inference.\n",
        "[Step 0] Number of frames available for inference: 307\n",
        "[Step 1] Using saved landmarks.\n",
        "  --outfile /content/my_outputs/test_result_safe.[Info] Using cuda for inference.\n",
        "[Step 0] Number of frames available for inference: 307\n",
        "[Step 1] Using saved landmarks.\n",
        "[Step 2] 3DMM Extraction In Video:: 100%|█| 307/307 [00:\n",
        "using expression center\n",
        "Load checkpoint from: checkpoints/DNet.pt\n",
        "[Step 1] Using saved landmarks.\n",
        "[Step 2] 3DMM Extraction In Video:: 100%|█| 307/307 [00:\n",
        "using expression center\n",
        "Load checkpoint from: checkpoints/DNet.pt\n",
        "Load checkpoint from: checkpoints/DNet.pt\n",
        "Load checkpoint from: checkpoints/LNet.pth\n",
        "Load checkpoint from: checkpoints/ENet.pth\n",
        "[Step 3] Using saved stabilized video.\n",
        "[Step 4] Load audio; Length of mel chunks: 311[Step 5] Reference Enhancement: 100%|█| 307/307 [00:48<0\n",
        "[Step 5] Reference Enhancement: 100%|█| 307/307 [00:48<0\n",
        "/307 [00:48<0\n",
        "landmark Det:: 100%|██| 307/307 [00:15<00:00, 19.83it/s]\n",
        "100%|██████████████| 307/307 [00:00<00:00, 15502.85it/s]\n",
        "100%|████████████████| 307/307 [00:00<00:00, 450.27it/s]\n",
        "FaceDet:: 100%|█████████| 77/77 [01:46<00:00,  1.38s/it]\n",
        "[Step 6] Lip Synthesis:: 100%|█| 20/20 [10:06<00:00, 30.\n",
        "outfile: /content/my_outputs/test_result_safe.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "content/video-retalking# python3 inference.py   --face /content/my_inputs/testvideo.mp4   --audio /content/my_inputs/testaudio.wav   --outfile /content/my_outputs/test_result_safe.mp4                                       \n",
        "[Info] Using cuda for inference.\n",
        "[Step 0] Number of frames available for inference: 340\n",
        "[Step 1] Using saved landmarks.\n",
        "[Step 2] 3DMM Extraction In Video::   7%| | 23/340 [[Step 2] 3DMM Extraction In Video::  10%| | 34[Step 2] 3DMM Extraction In Video::  13%[Step 2] 3DMM Extraction In Video::  16%|▏| 56[Step 2] 3DMM Extraction In Video:: [Step 2] 3DMM Extraction In Video::  2[Step 2] 3DMM Extraction In Video::  26%|▎|[Step 2] 3DMM Extraction In Video::  29%|▎|[Step 2] 3DMM Extraction In Video::  32%|▎|[Step 2] 3DMM Extraction In Video::  35%|▎|[Step 2] 3DMM Extraction In Video::  38%|▍|[Step 2] 3DMM Extraction In Video::  41%|▍|[Step 2] 3DMM Extraction In Video::  44%|▍|[Step 2] 3DMM Extraction In Video::  48%|▍|[Step 2] 3DMM Extraction In Video::  51%|▌|[Step 2] 3DMM Extraction In Video::  54%|▌|[Step 2] 3DMM Extraction In Video::  57%|▌|[Step 2] 3DMM Extraction In Video::  61%|▌|[Step 2] 3DMM Extraction In Video::  64%|▋|[Step 2] 3DMM Extraction In Video::  67%|▋|[Step 2] 3DMM Extraction In Video::  70%|▋|[Step 2] 3DMM Extraction In Video::  74%|▋|[Step 2] 3DMM Extraction In Video::  77%|▊|[Step 2] 3DMM Extraction In Video::  80%|▊|[Step 2] 3DMM Extraction In Video::  83%|▊|[Step 2] 3DMM Extraction In Video::  86%|▊|[Step 2] 3DMM Extraction In Video::  90%|▉|[Step 2] 3DMM Extraction In Video::  93%|▉|[Step 2] 3DMM Extraction In Video::  96%|▉|[Step 2] 3DMM Extraction In Video:: 100%|▉|[Step 2] 3DMM Extraction In Video:: 100%|█| 340/340 [00:\n",
        "using expression center\n",
        "Load checkpoint from: checkpoints/DNet.pt\n",
        "Load checkpoint from: checkpoints/LNet.pth\n",
        "Load checkpoint from: checkpoints/ENet.pth\n",
        "[Step 3] Stabilize the expression In Video:\n",
        "[Step 4] Load audio; Length of mel chunks: 312\n",
        "[Step 5] Reference Enhancement: 100%|█| 312\n",
        "landmark Det:: 100%|█| 312/312 [00:16<00:00\n",
        "100%|█| 312/312 [00:00<00:00, 15510.34it/s]\n",
        "100%|███| 312/312 [00:00<00:00, 459.88it/s]\n",
        "FaceDet:: 100%|█| 78/78 [00:49<00:00,  1.58\n",
        "[Step 6] Lip Synthesis:: 100%|█| 20/20 [05:\n",
        "outfile: /content/my_outputs/test_result_safe.mp4\n",
        "/content/video-retalking#\n"
      ],
      "metadata": {
        "id": "AjXq-cHO9P2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "while True:\n",
        "    time.sleep(60)\n",
        "    print(\"Still running...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuMHAgLN_l35",
        "outputId": "61231ca9-7db1-4936-a10e-a383e9b7ee26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Still running...\n",
            "Still running...\n",
            "Still running...\n",
            "Still running...\n",
            "Still running...\n",
            "Still running...\n",
            "Still running...\n",
            "Still running...\n",
            "Still running...\n",
            "Still running...\n",
            "Still running...\n",
            "Still running...\n",
            "Still running...\n",
            "Still running...\n",
            "Still running...\n",
            "Still running...\n",
            "Still running...\n",
            "Still running...\n"
          ]
        }
      ]
    }
  ]
}